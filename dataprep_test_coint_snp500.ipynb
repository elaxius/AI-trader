{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "from datetime import datetime"
   ],
   "id": "1c88172aff779930"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c9b18a6cf20b8c84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def download_yfinance_data(tickers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Download historical stock data from Yahoo Finance for the given tickers and date range.\n",
    "    Combine all data into a single DataFrame with a fixed daily index.\n",
    "    \"\"\"\n",
    "    date_dataframe = pd.DataFrame(pd.date_range(start=start_date, end=end_date, freq='D'), columns=['Date'])\n",
    "\n",
    "    for ticker in tqdm(tickers):\n",
    "        try:\n",
    "            data_ticker = yf.download(ticker, start=start_date, end=end_date, multi_level_index=False)\n",
    "            if not data_ticker.empty:\n",
    "                # Determine which column to use\n",
    "                close_column = 'Adj Close' if 'Adj Close' in data_ticker.columns else 'Close'\n",
    "                data_extract = data_ticker[[close_column]].rename(columns={close_column: ticker})\n",
    "                date_dataframe = date_dataframe.merge(data_extract, left_on='Date', right_index=True, how='left')\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {ticker}: {e}\")\n",
    "\n",
    "    return date_dataframe"
   ],
   "id": "ad0ee74eba13c5d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_all_tickers():\n",
    "    # API URL\n",
    "    url = \"https://api.nasdaq.com/api/screener/stocks?tableonly=true&download=true\"\n",
    "    # Headers (User-Agent is required to avoid access restrictions)\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    # Fetch data from the API\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract relevant rows\n",
    "    rows = data.get(\"data\", {}).get(\"rows\", [])\n",
    "\n",
    "    # Create DataFrame\n",
    "    df_result = pd.DataFrame(rows, columns=[\"symbol\", \"name\", \"country\", \"ipoyear\", \"industry\"])\n",
    "\n",
    "    # Display the first few rows\n",
    "    return df_result"
   ],
   "id": "30952be5b8ac5f14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c1e10c7746291ed0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# df = pd.read_csv(\"Data/yfinance_data.csv\")",
   "id": "7570dbae68f726e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# df_all_tickers = get_all_tickers() #6898",
   "id": "5783df639121b183"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# start_date = \"2024-01-01\"\n",
    "# end_date = \"2024-12-31\"\n",
    "# tickers = df_all_tickers['symbol'].to_list()  # Example tickers\n",
    "# # tickers = ['AAPL','MSFT','GOOGL']\n",
    "#\n",
    "# df = download_yfinance_data(tickers, start_date, end_date)\n",
    "#\n",
    "# if df is not None:\n",
    "#     df.to_csv(\"Data/yfinance_data.csv\")\n",
    "#     print(\"Data successfully downloaded and saved to yfinance_data.csv\")"
   ],
   "id": "62d9c52739dd4312"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# df = df.set_index('Date')\n",
    "# df_clean = df.dropna(axis=1, thresh=int(len(df.index)/2), inplace=False)\n",
    "# # df_filled = df_clean.interpolate(method='linear')\n",
    "# # c = df_filled.corr().abs()\n",
    "# c = df_clean.corr().abs()\n",
    "# # Remove self-correlation and keep only one side of the matrix\n",
    "# c = c.where(~np.tril(np.ones(c.shape), k=0).astype(bool))\n",
    "# s = c.unstack()\n",
    "# so = s.sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
    "# so.columns = ['ticker_1', 'ticker_2', 'correlation']\n",
    "# so.to_csv('ticker_correlations.zip')"
   ],
   "id": "19afd5e46925dabb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# so[so['correlation']<1]\n",
   "id": "6943a6245170e84e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "wiki_data=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies') # Open the link and download S&P company details in a table\n",
    "data = wiki_data[0] # All data is stored in first cell\n",
    "sorted_data = data.sort_values(by=['Symbol'], ascending=True) # Sort the dataframe on ticker in alphabetical ascending order\n",
    "# Convert the dataframe to csv file\n",
    "sorted_data.to_csv('Data/S&P500Tickers.csv', mode='w', index=False) #index is False as we don't want to write index in csv file\n",
    "sorted_data"
   ],
   "id": "de659dfaa65c3e9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Analysis on snp500 only\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2025-01-31\"\n",
    "tickers = sorted_data['Symbol'].to_list()  # Example tickers\n",
    "\n",
    "df = download_yfinance_data(tickers, start_date, end_date)\n",
    "\n",
    "if df is not None:\n",
    "    df.to_csv(\"Data/yfinance_snp500_data_202001_202501.csv\")\n",
    "    print(\"Data successfully downloaded and saved to yfinance_data.csv\")"
   ],
   "id": "af563976481875d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "84151f71ec8a6e78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = df.set_index('Date')",
   "id": "f2f1f1975b39db5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# df = df.set_index('Date')\n",
    "df_clean = df.dropna(axis=1, thresh=int(len(df.index)/2), inplace=False)\n",
    "# df_filled = df_clean.interpolate(method='linear')\n",
    "# c = df_filled.corr().abs()\n",
    "c = df_clean.corr().abs()\n",
    "# Remove self-correlation and keep only one side of the matrix\n",
    "c = c.where(~np.tril(np.ones(c.shape), k=0).astype(bool))\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
    "so.columns = ['ticker_1', 'ticker_2', 'correlation']\n",
    "so.to_csv('Data/snp500_correlations_202001_202501.zip')"
   ],
   "id": "29c54edfad74c79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# read csv files\n",
    "# df = pd.read_csv(\"yfinance_snp500_data_202001_202501.csv\")\n",
    "# so = pd.read_csv('snp500_correlations_202001_202501.zip')"
   ],
   "id": "f779aa05a04117c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "so[so['correlation']<1]",
   "id": "9b9211ef0f64433f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## check for cointegration\n",
    "def check_stationarity(series):\n",
    "    \"\"\"Returns the p-value from the Augmented Dickey-Fuller (ADF) test.\"\"\"\n",
    "    return adfuller(series)[1]  # ADF test p-value\n",
    "\n",
    "def calculate_cointegration(corr_df, timeseries_df):\n",
    "    \"\"\"\n",
    "    Takes in:\n",
    "    - corr_df: DataFrame with columns ['ticker1', 'ticker2', 'correl']\n",
    "    - timeseries_df: DataFrame where each column is a ticker's time series.\n",
    "\n",
    "    Adds three new columns:\n",
    "    - 'p1_stationary': ADF p-value for ticker1\n",
    "    - 'p2_stationary': ADF p-value for ticker2\n",
    "    - 'p_cointegration': Cointegration test p-value\n",
    "    \"\"\"\n",
    "\n",
    "    results = []  # Store results for efficient DataFrame construction\n",
    "\n",
    "    for index, row in corr_df.iterrows():\n",
    "        t1, t2 = row[\"ticker_1\"], row[\"ticker_2\"]\n",
    "\n",
    "        # Get time series data\n",
    "        series1 = timeseries_df[t1].dropna()\n",
    "        series2 = timeseries_df[t2].dropna()\n",
    "\n",
    "        # Ensure both series have the same length\n",
    "        min_len = min(len(series1), len(series2))\n",
    "        series1, series2 = series1.iloc[-min_len:], series2.iloc[-min_len:]\n",
    "\n",
    "        # Check stationarity (ADF test)\n",
    "        p1 = check_stationarity(series1)\n",
    "        p2 = check_stationarity(series2)\n",
    "\n",
    "        # Check cointegration only if both series are non-stationary (p > 0.05)\n",
    "        if p1 > 0.05 and p2 > 0.05:\n",
    "            p_cointegration1 = coint(series1, series2, trend='c')[1]  # Engle-Granger test p-value\n",
    "            p_cointegration2 = coint(series2, series1, trend='c')[1]\n",
    "        else:\n",
    "            p_cointegration1 = np.nan  # Not applicable\n",
    "            p_cointegration2 = np.nan\n",
    "\n",
    "        results.append((t1, t2, p1, p2, p_cointegration1, p_cointegration2))\n",
    "\n",
    "    # Convert results into DataFrame and merge with original correlation DataFrame\n",
    "    results_df = pd.DataFrame(results, columns=[\"ticker_1\", \"ticker_2\", \"p1_stationary\", \"p2_stationary\", \"p_cointegration1\", \"p_cointegration2\"])\n",
    "    return corr_df.merge(results_df, on=[\"ticker_1\", \"ticker_2\"])\n",
    "\n",
    "corr_df = calculate_cointegration(so, df)\n",
    "corr_df.to_csv('Data/SnP500cointegration_results_temp2.csv')\n",
    "corr_df['p_coint_avg'] = corr_df[['p_cointegration1', 'p_cointegration2']].mean(axis=1, skipna=True)\n",
    "corr_df['p_coint_min'] = corr_df[['p_cointegration1', 'p_cointegration2']].min(axis=1, skipna=True)\n",
    "corr_df['p_coint_max'] = corr_df[['p_cointegration1', 'p_cointegration2']].max(axis=1, skipna=True)\n",
    "corr_df.to_csv('Data/SnP500cointegration_results_202001_202501.csv')"
   ],
   "id": "123efd015e32f6bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "promising_pairs1 = corr_df[(corr_df['p_coint_max']>0) &\n",
    "        (corr_df['p_coint_max']<0.01) &\n",
    "        (corr_df['p1_stationary']>=0.05) &\n",
    "        (corr_df['p2_stationary']>=0.05) &\n",
    "        (~corr_df['correlation'].isna())\n",
    "        ].sort_values(by='p_coint_max', ascending=True)"
   ],
   "id": "bdd053b95ec83e0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "promising_pairs1['regress1on2'] = promising_pairs1['p_cointegration1'] < promising_pairs1['p_cointegration2']",
   "id": "5464dd0c8e0cb007"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "promising_pairs1",
   "id": "a2399a7bc0d9247e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "76b9ab5c4581a12c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_dual_axis(df, ticker1, ticker2):\n",
    "    \"\"\"\n",
    "    Plots two time series on separate y-axes.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the time series.\n",
    "        ticker1 (str): First ticker (plotted on left y-axis).\n",
    "        ticker2 (str): Second ticker (plotted on right y-axis).\n",
    "    \"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # First time series (ticker1)\n",
    "    ax1.plot(df.index, df[ticker1], marker=\".\", markersize=1, color=\"b\", label=ticker1)\n",
    "    ax1.set_xlabel(\"Date\")\n",
    "    ax1.set_ylabel(f\"{ticker1} Value\", color=\"b\")\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=\"b\")\n",
    "    ax1.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # Second time series (ticker2) on secondary y-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(df.index, df[ticker2], marker=\".\", markersize=1, color=\"r\", label=ticker2)\n",
    "    ax2.set_ylabel(f\"{ticker2} Value\", color=\"r\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"r\")\n",
    "\n",
    "    # Legend\n",
    "    fig.legend(loc=\"upper left\", bbox_to_anchor=(0.1, 0.9))\n",
    "    plt.title(f\"{ticker1} vs {ticker2} Time Series\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ],
   "id": "1aae0f92da5e91a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_same_axis(df, ticker1, ticker2, factor1=1, factor2=1):\n",
    "    \"\"\"\n",
    "    Plots two time series on the same y-axis.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the time series.\n",
    "        ticker1 (str): First ticker to plot.\n",
    "        ticker2 (str): Second ticker to plot.\n",
    "        factor1 (float, optional): Multiplicative factor for the first series. Default is 1.\n",
    "        factor2 (float, optional): Multiplicative factor for the second series. Default is 1.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Plot both series on the same axis\n",
    "    ax.plot(df.index, df[ticker1] * factor1, marker=\".\", markersize=1, color=\"b\", label=ticker1)\n",
    "    ax.plot(df.index, df[ticker2] * factor2, marker=\".\", markersize=1, color=\"r\", label=ticker2)\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    ax.set_title(f\"{ticker1} vs {ticker2} Time Series\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ],
   "id": "79da8d7cf2621a9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_dual_axis(df, \"ADP\", \"BKR\")  # Pass any two tickers\n",
   "id": "6d34af3695fdbe04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7db1b04da45fad23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "43696ea6fb4c9019"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_cointegration_factor(ticker_1_series, ticker_2_series, f_1on2):\n",
    "    \"\"\"\n",
    "    Calculates the cointegration factor (β) using OLS regression without an intercept.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing time series data.\n",
    "        ticker_1 (str): Independent variable.\n",
    "        ticker_2 (str): Dependent variable.\n",
    "        f_1on2 (bool): Determines if its series1~series2 or series2~series1\n",
    "\n",
    "    Returns:\n",
    "        float: Cointegration factor (β), or NaN if computation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        series1 = ticker_1_series.dropna()\n",
    "        series2 = ticker_2_series.dropna()\n",
    "\n",
    "        # Ensure both series have the same length\n",
    "        min_len = min(len(series1), len(series2))\n",
    "        if min_len < 20:\n",
    "            return np.nan  # Not enough data points\n",
    "\n",
    "        series1, series2 = series1.iloc[-min_len:], series2.iloc[-min_len:]\n",
    "        if (f_1on2):\n",
    "            # OLS Regression: ticker_1 ~ ticker_2 (without intercept)\n",
    "            model = sm.OLS(series1, series2, hasconst=True).fit()\n",
    "        else:\n",
    "            model = sm.OLS(series2, series1, hasconst=True).fit()\n",
    "        return model.params[0]  # Extract β coefficient (slope)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Exception occurred \",e )\n",
    "        return np.nan  # Return NaN if an error occurs"
   ],
   "id": "b1229ad7a9123967"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "promising_pairs1['coint_factor'] = promising_pairs1.apply(lambda row: get_cointegration_factor(df[row['ticker_1']], df[row['ticker_2']], row['regress1on2']), axis=1)\n",
   "id": "7602d5f6d8300a29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "promising_pairs1.to_csv('Data/promising_pairs1.csv', index=False)",
   "id": "cea136e974d5224c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "promising_pairs1.head()",
   "id": "ba76bcc69a01de93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_dual_axis(df, \"ADP\", \"BKR\")",
   "id": "ed6be1c27519b7c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "get_cointegration_factor(df['ADP'], df['BKR'],True)",
   "id": "82ff4551f609b844"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_same_axis(df, \"ADP\", \"BKR\",0.12744798758111703, 1)",
   "id": "a23864c39b89d292"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_residuals(series_y, series_x, beta):\n",
    "\n",
    "\n",
    "    residuals = series_y / (beta * series_x) - 1\n",
    "    mean = residuals.mean()\n",
    "    std = residuals.std()\n",
    "    residuals_std = (residuals - mean) / std\n",
    "    return residuals, residuals_std, mean, std"
   ],
   "id": "500bb730394fc693"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "promising_pairs1[['coint_resid_mean', 'coint_resid_std']] = promising_pairs1.apply(\n",
    "    lambda row: pd.Series(\n",
    "        calculate_residuals(df[row['ticker_1']], df[row['ticker_2']], row['coint_factor'])[2:4]\n",
    "        if row['regress1on2']\n",
    "        else calculate_residuals(df[row['ticker_2']], df[row['ticker_1']], row['coint_factor'])[2:4]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n"
   ],
   "id": "ccbf7c90c39b66b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "promising_pairs1['current']",
   "id": "3a6679ded40adac1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "798ee2b0706b53c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_latest_resid(symbol_y, symbol_x, beta, mean, std):\n",
    "    latest_y = yf.Ticker(symbol_y).fast_info['lastPrice']\n",
    "    latest_x = yf.Ticker(symbol_x).fast_info['lastPrice']\n",
    "    latest_resid = latest_y / (beta * latest_x) - 1\n",
    "    return (latest_resid - mean)/std\n",
    "\n",
    "promising_pairs1['current_signal'] = promising_pairs1.apply(lambda row: get_latest_resid(row['ticker_1'], row['ticker_2'], row['coint_factor'], row['coint_resid_mean'], row['coint_resid_std']) if row['regress1on2'] else get_latest_resid(row['ticker_2'], row['ticker_1'], row['coint_factor'], row['coint_resid_mean'], row['coint_resid_std']), axis=1)\n"
   ],
   "id": "febca7aee3466b84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "promising_pairs1[promising_pairs1['current_signal'].abs() > 2.5]",
   "id": "41f09cbeb0f3cfe2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "calculate_residuals(df['MO'], df['PM'],2.2562831761575657)[1].plot()",
   "id": "3c00c701b537f276"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_same_axis(df, \"MO\", \"PM\",2.2562831761575657,1)",
   "id": "bbde1727b46da469"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ticker_1, factor_1 = 'MO',2.2562831761575657\n",
    "ticker_2, factor_2 = 'PM',1\n",
    "\n",
    "\n",
    "ticker_1_latest = yf.Ticker(ticker_1).fast_info['lastPrice']\n",
    "ticker_2_latest = yf.Ticker(ticker_2).fast_info['lastPrice']\n",
    "midpoint = (ticker_1_latest*factor_1 + ticker_2_latest*factor_2)/2\n",
    "\n",
    "print(f\"ticker {ticker_1} latest price is {ticker_1_latest}\")\n",
    "print(f\"ticker {ticker_2} latest price is {ticker_2_latest}\")\n",
    "print(f\"Average middle is {midpoint}, which is {midpoint/factor_1} for {ticker_1} and {midpoint/factor_2} for {ticker_2}\")\n",
    "\n"
   ],
   "id": "e99617ce1063d9b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['AVGO']",
   "id": "140d934fc0d87207"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#download live latest data\n",
    "ticker_1 = 'JPM'\n",
    "ticker_2 = 'RL'\n",
    "ticker_1_live = yf.Ticker(ticker_1).history(interval = '1d', period='1y')[['Close']].rename(columns={'Close':f'close_{ticker_1}'})\n",
    "ticker_2_live = yf.Ticker(ticker_2).history(interval = '1d', period='1y')[['Close']].rename(columns={'Close':f'close_{ticker_2}'})\n",
    "ticker = ticker_1_live.merge(ticker_2_live, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "plot_same_axis(ticker, f'close_{ticker_1}', f'close_{ticker_2}',1,1.174558)"
   ],
   "id": "2a8629c4dcaca18b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_same_axis(df, \"MO\", \"PM\",2.2562831761575657,1)",
   "id": "4c9ecfb49c7fe38b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "yf.Ticker('S68.SI').news",
   "id": "97888639800e3a8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "122d44295fdcdb66"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
